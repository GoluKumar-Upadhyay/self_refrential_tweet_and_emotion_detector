{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PH6wwRnaYV_"
      },
      "outputs": [],
      "source": [
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.3.0 transformers==4.41.2 huggingface_hub --upgrade\n"
      ],
      "metadata": {
        "id": "usdV_j9Se-7V",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import re\n",
        "import emoji"
      ],
      "metadata": {
        "id": "etaU_Uvee-xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv(\"Final_data.csv\", encoding='latin1')"
      ],
      "metadata": {
        "id": "Ygtbtb0pe-l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(4)"
      ],
      "metadata": {
        "id": "4p-hrobQfFUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df[\"Category\"].value_counts()"
      ],
      "metadata": {
        "id": "UeFkZzbzfFRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df[\"Category\"])"
      ],
      "metadata": {
        "id": "5hebwdp7fFOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def clean_texts(text):\n",
        "    cleantext = emoji.replace_emoji(text, replace='')\n",
        "    cleantext = re.sub(r'http\\S+\\s', ' ', text)\n",
        "    cleantext = re.sub(r'@\\S+', ' ', cleantext)\n",
        "    cleantext = re.sub(r'#\\S+', ' ', cleantext)\n",
        "    cleantext = re.sub(r'@\\S+', ' ', cleantext)\n",
        "    cleantext = re.sub(r'[%s]' % re.escape(r\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', cleantext)\n",
        "    cleantext = re.sub(r'[0-9]+', ' ', cleantext)\n",
        "    cleantext = re.sub(r'[^\\x00-\\x7f]', r' ', cleantext)\n",
        "    cleantext = re.sub(r'\\s+', ' ', cleantext)\n",
        "    return cleantext"
      ],
      "metadata": {
        "id": "Ta88wl-JfObs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_texts(\"11 Remember when your mom said eating all that junk food was going to make you sick? Well, she wasn't wrong. Anxiety, depression, mental disorders are really gut #biome disorders. #LoveYourBiome  https://www.bbc.com/news/health-43815370ÃÂ Ã¢ÂÂ¦\")"
      ],
      "metadata": {
        "id": "nnAjV2fpfOYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text\"]= df[\"text\"].apply(lambda x: clean_texts(x))"
      ],
      "metadata": {
        "id": "0jLuP5w0fOVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text\"][10]"
      ],
      "metadata": {
        "id": "m7Z9ibcnfOSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['Category'] = label_encoder.fit_transform(df['Category'])"
      ],
      "metadata": {
        "id": "PLvL4wP4fOO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BERT**"
      ],
      "metadata": {
        "id": "iuUJTt4z8ZNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert_model.eval()\n",
        "\n",
        "embeddings_list = []\n",
        "\n",
        "for text in tqdm(df['text'], desc=\"Encoding tweets\"):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=256)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
        "    embeddings_list.append(cls_embedding)\n",
        "\n",
        "df[\"bert_embedding\"] = embeddings_list\n"
      ],
      "metadata": {
        "id": "rSgb5eSMfOMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"bert_embedding\"].head(5)"
      ],
      "metadata": {
        "id": "ap8YF-UFfOJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Bidirectional\n",
        "\n",
        "X = np.stack(df['bert_embedding'].values)\n",
        "y = df['Category'].values\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n"
      ],
      "metadata": {
        "id": "2fCf3LM9fOGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BERT + BI-LSTM**\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Lrgnwx1n0qoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Bidirectional, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "input_dim = 768  # BERT CLS embedding size\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "inputs = Input(shape=(input_dim,), name='bert_input')\n",
        "\n",
        "# Replace Lambda with Reshape\n",
        "x = Reshape((1, input_dim))(inputs)\n",
        "\n",
        "x = Bidirectional(LSTM(64, return_sequences=False))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "EXwLNw2JfODI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    batch_size=32,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "id": "bidKZS7CfN_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PKw9NlNHnvBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred_probs = model.predict(X_test)\n",
        "\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7LidtjrNod63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, acc, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zjRQxq1gqqKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "\n",
        "\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(BERT + LSTM) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wD9Ei6i9orbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BERT + LSTM**"
      ],
      "metadata": {
        "id": "NyYCA1j2pWqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "input_dim = 768\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "\n",
        "inputs = Input(shape=(input_dim,), name='bert_input')\n",
        "x = Reshape((1, input_dim))(inputs)\n",
        "x = LSTM(128, return_sequences=False)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    batch_size=32,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "id": "MaZ9g3zTpWPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "\n",
        "if len(y_test.shape) > 1 and y_test.shape[1] > 1:\n",
        "    y_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, acc, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(BERT + LSTM) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FwP7MBy9rSHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H3EapMgjrqvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BERT + BILSTM**"
      ],
      "metadata": {
        "id": "e-2ndhbxs7O3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Bidirectional, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "input_dim = 768\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "inputs = Input(shape=(input_dim,), name='bert_input')\n",
        "x = Reshape((1, input_dim))(inputs)\n",
        "x = Bidirectional(LSTM(128, return_sequences=False))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    batch_size=32,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "id": "e25bVKHFtDEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "\n",
        "if len(y_test.shape) > 1 and y_test.shape[1] > 1:\n",
        "    y_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, acc, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(BERT + BILSTM) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BJdQOKeGt4f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iVen-5Rwt459"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BERT + GRU**"
      ],
      "metadata": {
        "id": "tqgH5U7Euyxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Dropout, GRU, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "input_dim = 768\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "inputs = Input(shape=(input_dim,), name='bert_input')\n",
        "\n",
        "# Reshape to fit GRU input (timesteps=1, features=input_dim)\n",
        "x = Reshape((1, input_dim))(inputs)\n",
        "x = GRU(128, return_sequences=False)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model_GRU = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "\n",
        "model_GRU.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "model_GRU.summary()\n",
        "\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "\n",
        "history = model_GRU.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    batch_size=32,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "id": "80c-oFBvuwk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "y_pred_probs = model_GRU.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "\n",
        "if len(y_test.shape) > 1 and y_test.shape[1] > 1:\n",
        "    y_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, acc, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(BERT + GRU) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VvWnGUZBu3tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FC9ukhZ6vYTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BERT + BIGRU**"
      ],
      "metadata": {
        "id": "tRo54zmbva_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Dropout, GRU, Bidirectional, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "input_dim = 768\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "\n",
        "inputs = Input(shape=(input_dim,), name='bert_input')\n",
        "\n",
        "\n",
        "x = Reshape((1, input_dim))(inputs)\n",
        "x = Bidirectional(GRU(128, return_sequences=False))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    batch_size=32,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "id": "rBQIEOIavdbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "\n",
        "if len(y_test.shape) > 1 and y_test.shape[1] > 1:\n",
        "    y_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, acc, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(BERT + BIGRU) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9ekKTZHgv2YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BERT + Logistic regression**"
      ],
      "metadata": {
        "id": "oE_OizJlwUFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "clf = LogisticRegression(max_iter=2000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "2LWa-xIVv4vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rOWhRBtywOgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(Logistic regression) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZtEzyVzJwmdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W7IReIsEwqpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BERT + Randomforest classifier**"
      ],
      "metadata": {
        "id": "1HMF9LFkxS4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "r_clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "r_clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "JtziYOEXxYDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "y_pred = r_clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(Randomforest classifier) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0oSVsRdrxb-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cq97qyl6yDUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BERT + XGBOOST**"
      ],
      "metadata": {
        "id": "l4Fqa1QMyLCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "clf_xgb = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "clf_xgb.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "znwLvgrkyOjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "y_pred = r_clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(Randomforest classifier) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2FspKknWyhEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H4U3va1gzAMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BERT + Lightgbm**"
      ],
      "metadata": {
        "id": "sDcfUu7GzB1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "clf_lgb =LGBMClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "clf_lgb.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "JprBQwH8zFRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "y_pred = clf_lgb.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(Randomforest classifier) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hYFDIqp9zO_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G4iy3ZbBz0f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SBERT + LSTM**"
      ],
      "metadata": {
        "id": "6xYfmVEC0Njf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text\"].head(4)"
      ],
      "metadata": {
        "id": "sOowTbZi27HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall sentence-transformers transformers huggingface_hub -y\n"
      ],
      "metadata": {
        "id": "vxwVJBan6vY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y transformers sentence-transformers huggingface_hub\n"
      ],
      "metadata": {
        "id": "VyD7zoo77Bsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub==0.16.4\n",
        "!pip install transformers==4.33.1\n",
        "!pip install sentence-transformers==2.2.2\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fleGNlCt62vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install --upgrade sentence-transformers\n"
      ],
      "metadata": {
        "id": "-aR-RZuc72xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"SBERT loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "F0q7rZBG6UJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FtMKvpO53VtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KukrwbMxANnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_cleaned = label_encoder.fit_transform(y_raw)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = sbert_model.encode(X_cleaned, batch_size=16,\n",
        "                                show_progress_bar=True)\n",
        "\n",
        "X = embeddings.reshape((embeddings.shape[0], 1, embeddings.shape[1]))\n",
        "y = y_cleaned\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "inputs = Input(shape=(X.shape[1], X.shape[2]))\n",
        "x = LSTM(128, return_sequences=False, kernel_regularizer=regularizers.l2(1e-4))(inputs)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=20, batch_size=16,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1)\n",
        "\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "j7I1oq0N0SL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "y_pred_prob = model.predict(X_test, batch_size=20)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (SBERT + LSTM)\")\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(SBERT + LSTM) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "etfIU0xJ8mTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, acc, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uGRsVIEc_xwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RbSOfZLZAJMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SBERT + BILSTM**"
      ],
      "metadata": {
        "id": "ENVpfA1UAQJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Bidirectional, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_cleaned = label_encoder.fit_transform(y_raw)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = sbert_model.encode(X_cleaned, batch_size=16,\n",
        "                                show_progress_bar=True)\n",
        "\n",
        "X = embeddings.reshape((embeddings.shape[0], 1, embeddings.shape[1]))\n",
        "y = y_cleaned\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "inputs = Input(shape=(X.shape[1], X.shape[2]))\n",
        "x = Bidirectional(LSTM(64, return_sequences=False, kernel_regularizer=regularizers.l2(1e-4)))(inputs)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=20, batch_size=16,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1)\n",
        "\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "lpniNObEATl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "y_pred_prob = model.predict(X_test, batch_size=20)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (SBERT + BILSTM)\")\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(SBERT + BILSTM) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tNbMc1bgBErt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, acc, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KhYt_xgcBFB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SVNU6KqFBKSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SBERT + GRU**"
      ],
      "metadata": {
        "id": "cT2rM3xgBMBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_cleaned = label_encoder.fit_transform(y_raw)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = sbert_model.encode(X_cleaned, batch_size=16,\n",
        "                                show_progress_bar=True)\n",
        "\n",
        "X = embeddings.reshape((embeddings.shape[0], 1, embeddings.shape[1]))\n",
        "y = y_cleaned\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "inputs = Input(shape=(X.shape[1], X.shape[2]))\n",
        "x = GRU(64, return_sequences=False, kernel_regularizer=regularizers.l2(1e-4))(inputs)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=20, batch_size=16,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1)\n",
        "\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "coCRIk7rBO9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "y_pred_prob = model.predict(X_test, batch_size=20)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (SBERT + GRU)\")\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(SBERT + GRU) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IiKDmSHFBlhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, acc, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k6fc2noqBqjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nPa4-fK1CtQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SBERT + BIGRU**"
      ],
      "metadata": {
        "id": "OApTP944CuTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, GRU, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_cleaned = label_encoder.fit_transform(y_raw)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = sbert_model.encode(X_cleaned, batch_size=16,\n",
        "                                show_progress_bar=True)\n",
        "\n",
        "X = embeddings.reshape((embeddings.shape[0], 1, embeddings.shape[1]))\n",
        "y = y_cleaned\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "inputs = Input(shape=(X.shape[1], X.shape[2]))\n",
        "x = Bidirectional(GRU(64, return_sequences=False, kernel_regularizer=regularizers.l2(1e-4)))(inputs)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=20, batch_size=16,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1)\n",
        "\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "s4obdFPiCw_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "y_pred_prob = model.predict(X_test, batch_size=20)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (SBERT + BIGRU)\")\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(SBERT + BIGRU) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "h8oskEh0DE1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, acc, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UcQm68mPDErD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SBERT + Logistic regression**"
      ],
      "metadata": {
        "id": "T-4syLhlDPIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_cleaned = label_encoder.fit_transform(y_raw)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = sbert_model.encode(X_cleaned, batch_size=16, show_progress_bar=True)\n",
        "\n",
        "X = embeddings  # keep 2D\n",
        "y = np.array(y_cleaned)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "clf = LogisticRegression(max_iter=2000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "4pbUZ8GGDOst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (SBERT + BIGRU)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"Logistic Regression Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1vScKS53Drvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vWOOQuKpEvZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SBERT + xgboost**"
      ],
      "metadata": {
        "id": "qiIl5LDqGAb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_cleaned = label_encoder.fit_transform(y_raw)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = sbert_model.encode(X_cleaned, batch_size=16, show_progress_bar=True)\n",
        "\n",
        "X = embeddings  # keep 2D\n",
        "y = np.array(y_cleaned)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(\"[INFO] Training XGBoost classifier...\")\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NusO9QubGFz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (SBERT + xgboost)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"xgboost Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p-JIqWJ9GYTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LemfR_ZqGvnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **sbert + Randomforest classifier**"
      ],
      "metadata": {
        "id": "tC3ywYNnGxXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_cleaned = label_encoder.fit_transform(y_raw)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = sbert_model.encode(X_cleaned, batch_size=16, show_progress_bar=True)\n",
        "\n",
        "X = embeddings  # keep 2D\n",
        "y = np.array(y_cleaned)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "print(\"[INFO] Training Random Forest classifier...\")\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=300,       # number of trees\n",
        "    max_depth=20,           # limit depth to avoid overfitting\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "efNyQmT5G2iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "y_pred = rf_model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (SBERT + xgboost)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"xgboost Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6pLFKwqkHRVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gQgoVPHKH6sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SBERT + SVM**"
      ],
      "metadata": {
        "id": "BbGUbmCZJgUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_cleaned = label_encoder.fit_transform(y_raw)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = sbert_model.encode(X_cleaned, batch_size=16, show_progress_bar=True)\n",
        "\n",
        "X = embeddings\n",
        "y = np.array(y_cleaned)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(\"[INFO] Training SVM classifier...\")\n",
        "svm_model = SVC(\n",
        "    kernel='rbf',       # radial basis function kernel\n",
        "    C=10.0,             # regularization parameter\n",
        "    gamma='scale',      # kernel coefficient\n",
        "    probability=True,   # needed if you want predict_proba\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "aiOU86LBJgw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "y_pred = svm_model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (SBERT + xgboost)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"xgboost Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0lAsfE0zJzuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DistilBert + LSTM**"
      ],
      "metadata": {
        "id": "lg7E4OzsJ_B3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 5\n",
        "LR = 1e-4\n",
        "\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_cleaned = label_encoder.fit_transform(y_raw)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y = np.array(y_cleaned)\n",
        "\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "distilbert = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\", from_pt=True)\n",
        "distilbert.trainable = False\n",
        "\n",
        "encodings = tokenizer(\n",
        "    X_cleaned,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors=\"tf\"\n",
        ")\n",
        "\n",
        "input_ids = encodings[\"input_ids\"].numpy()\n",
        "attention_mask = encodings[\"attention_mask\"].numpy()\n",
        "\n",
        "\n",
        "X_train_ids, X_test_ids, X_train_mask, X_test_mask, y_train, y_test = train_test_split(\n",
        "    input_ids, attention_mask, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "class DistilBertEmbeddingLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, distilbert_model, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.distilbert = distilbert_model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_ids, attention_mask = inputs\n",
        "        outputs = self.distilbert(input_ids, attention_mask=attention_mask)\n",
        "        return outputs.last_hidden_state  # shape: (batch, seq_len, 768)\n",
        "\n",
        "\n",
        "input_ids_layer = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_ids\")\n",
        "attention_mask_layer = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"attention_mask\")\n",
        "\n",
        "\n",
        "bert_embeddings = DistilBertEmbeddingLayer(distilbert)([input_ids_layer, attention_mask_layer])\n",
        "\n",
        "x = LSTM(64, return_sequences=False, kernel_regularizer=regularizers.l2(1e-4))(bert_embeddings)\n",
        "x = Dropout(0.6)(x)\n",
        "x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "x = Dropout(0.6)(x)\n",
        "outputs = Dense(num_classes, activation=\"softmax\")(x)  # Softmax for multi-class\n",
        "\n",
        "\n",
        "model = Model(inputs=[input_ids_layer, attention_mask_layer], outputs=outputs)\n",
        "model.compile(optimizer=Adam(learning_rate=LR), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train_ids, X_train_mask], y_train,\n",
        "    validation_data=([X_test_ids, X_test_mask], y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate([X_test_ids, X_test_mask], y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "Gj6Y479PJ-Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "y_pred_prob = model.predict([X_test_ids, X_test_mask], batch_size=20)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (DISTILBERT + LSTM)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(DISTILBERT + LSTM) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Fl8Ku8-9fYyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, acc, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xU439r80LqmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ps9nxclZfi7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DISTILBERT + BILSTM**"
      ],
      "metadata": {
        "id": "ZNa5NGJh8BsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 5\n",
        "LR = 1e-4\n",
        "\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_cleaned = label_encoder.fit_transform(y_raw)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y = np.array(y_cleaned)\n",
        "\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "distilbert = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\", from_pt=True)\n",
        "distilbert.trainable = False\n",
        "\n",
        "encodings = tokenizer(\n",
        "    X_cleaned,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors=\"tf\"\n",
        ")\n",
        "\n",
        "input_ids = encodings[\"input_ids\"].numpy()\n",
        "attention_mask = encodings[\"attention_mask\"].numpy()\n",
        "\n",
        "\n",
        "X_train_ids, X_test_ids, X_train_mask, X_test_mask, y_train, y_test = train_test_split(\n",
        "    input_ids, attention_mask, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "class DistilBertEmbeddingLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, distilbert_model, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.distilbert = distilbert_model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_ids, attention_mask = inputs\n",
        "        outputs = self.distilbert(input_ids, attention_mask=attention_mask)\n",
        "        return outputs.last_hidden_state  # shape: (batch, seq_len, 768)\n",
        "\n",
        "\n",
        "input_ids_layer = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_ids\")\n",
        "attention_mask_layer = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"attention_mask\")\n",
        "\n",
        "\n",
        "bert_embeddings = DistilBertEmbeddingLayer(distilbert)([input_ids_layer, attention_mask_layer])\n",
        "\n",
        "x = Bidirectional(\n",
        "    LSTM(64, return_sequences=False, kernel_regularizer=regularizers.l2(3e-5)))(bert_embeddings)\n",
        "x = Dropout(0.6)(x)\n",
        "x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "x = Dropout(0.6)(x)\n",
        "outputs = Dense(num_classes, activation=\"softmax\")(x)  # Softmax for multi-class\n",
        "\n",
        "\n",
        "model = Model(inputs=[input_ids_layer, attention_mask_layer], outputs=outputs)\n",
        "model.compile(optimizer=Adam(learning_rate=LR), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train_ids, X_train_mask], y_train,\n",
        "    validation_data=([X_test_ids, X_test_mask], y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate([X_test_ids, X_test_mask], y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "y69y-xQZ8Ebl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "y_pred_prob = model.predict([X_test_ids, X_test_mask], batch_size=20)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (DISTILBERT + BILSTM)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(DISTILBERT + BILSTM) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6dUWIPAARx0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, acc, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oFJbMQ6QR1JP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DISTILBERT + GRU**"
      ],
      "metadata": {
        "id": "MEY3wi30S3k4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Bidirectional,GRU\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 5\n",
        "LR = 1e-4\n",
        "\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_cleaned = label_encoder.fit_transform(y_raw)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y = np.array(y_cleaned)\n",
        "\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "distilbert = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\", from_pt=True)\n",
        "distilbert.trainable = False\n",
        "\n",
        "encodings = tokenizer(\n",
        "    X_cleaned,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors=\"tf\"\n",
        ")\n",
        "\n",
        "input_ids = encodings[\"input_ids\"].numpy()\n",
        "attention_mask = encodings[\"attention_mask\"].numpy()\n",
        "\n",
        "\n",
        "X_train_ids, X_test_ids, X_train_mask, X_test_mask, y_train, y_test = train_test_split(\n",
        "    input_ids, attention_mask, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "class DistilBertEmbeddingLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, distilbert_model, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.distilbert = distilbert_model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_ids, attention_mask = inputs\n",
        "        outputs = self.distilbert(input_ids, attention_mask=attention_mask)\n",
        "        return outputs.last_hidden_state  # shape: (batch, seq_len, 768)\n",
        "\n",
        "\n",
        "input_ids_layer = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_ids\")\n",
        "attention_mask_layer = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"attention_mask\")\n",
        "\n",
        "\n",
        "bert_embeddings = DistilBertEmbeddingLayer(distilbert)([input_ids_layer, attention_mask_layer])\n",
        "\n",
        "x = GRU(64, return_sequences=False, kernel_regularizer=regularizers.l2(1e-4))(bert_embeddings)\n",
        "x = Dropout(0.6)(x)\n",
        "x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "x = Dropout(0.6)(x)\n",
        "outputs = Dense(num_classes, activation=\"softmax\")(x)  # Softmax for multi-class\n",
        "\n",
        "\n",
        "model = Model(inputs=[input_ids_layer, attention_mask_layer], outputs=outputs)\n",
        "model.compile(optimizer=Adam(learning_rate=LR), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train_ids, X_train_mask], y_train,\n",
        "    validation_data=([X_test_ids, X_test_mask], y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate([X_test_ids, X_test_mask], y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "E7VAPVhTS3QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "y_pred_prob = model.predict([X_test_ids, X_test_mask], batch_size=20)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (DISTILBERT + GRU)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(DISTILBERT + GRU) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LT7aDpBcS2ZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, acc, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ku4ei9yGmp7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d2aQPl9PnsNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DISTILBERT + BIGRU**"
      ],
      "metadata": {
        "id": "5cpkfqslnpiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Bidirectional,GRU\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 5\n",
        "LR = 1e-4\n",
        "\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_cleaned = label_encoder.fit_transform(y_raw)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y = np.array(y_cleaned)\n",
        "\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "distilbert = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\", from_pt=True)\n",
        "distilbert.trainable = False\n",
        "\n",
        "encodings = tokenizer(\n",
        "    X_cleaned,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors=\"tf\"\n",
        ")\n",
        "\n",
        "input_ids = encodings[\"input_ids\"].numpy()\n",
        "attention_mask = encodings[\"attention_mask\"].numpy()\n",
        "\n",
        "\n",
        "X_train_ids, X_test_ids, X_train_mask, X_test_mask, y_train, y_test = train_test_split(\n",
        "    input_ids, attention_mask, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "class DistilBertEmbeddingLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, distilbert_model, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.distilbert = distilbert_model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_ids, attention_mask = inputs\n",
        "        outputs = self.distilbert(input_ids, attention_mask=attention_mask)\n",
        "        return outputs.last_hidden_state  # shape: (batch, seq_len, 768)\n",
        "\n",
        "\n",
        "input_ids_layer = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_ids\")\n",
        "attention_mask_layer = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"attention_mask\")\n",
        "\n",
        "\n",
        "bert_embeddings = DistilBertEmbeddingLayer(distilbert)([input_ids_layer, attention_mask_layer])\n",
        "\n",
        "x = Bidirectional(\n",
        "        GRU(128, return_sequences=False, kernel_regularizer=regularizers.l2(1e-4))\n",
        "    )(bert_embeddings)\n",
        "x = Dropout(0.6)(x)\n",
        "x = Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "x = Dropout(0.6)(x)\n",
        "outputs = Dense(num_classes, activation=\"softmax\")(x)  # Softmax for multi-class\n",
        "\n",
        "\n",
        "model = Model(inputs=[input_ids_layer, attention_mask_layer], outputs=outputs)\n",
        "model.compile(optimizer=Adam(learning_rate=LR), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train_ids, X_train_mask], y_train,\n",
        "    validation_data=([X_test_ids, X_test_mask], y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate([X_test_ids, X_test_mask], y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "H_-ExiuHnsdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "y_pred_prob = model.predict([X_test_ids, X_test_mask], batch_size=20)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (DISTILBERT + BIGRU)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(DISTILBERT + BIGRU) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hDMWkdgL9V_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, acc, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kAt_c3B09boM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AMwlTnuu-Mga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tYUESXkq-QSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DISTILBERT + Logistic regression**"
      ],
      "metadata": {
        "id": "rQI-0L6p-QBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tqdm import tqdm\n",
        "\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y_raw)\n",
        "\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "distilbert = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\", from_pt=True)\n",
        "distilbert.trainable = False\n",
        "\n",
        "\n",
        "encodings = tokenizer(\n",
        "    X_cleaned,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors=\"tf\"\n",
        ")\n",
        "\n",
        "input_ids = encodings[\"input_ids\"]\n",
        "attention_mask = encodings[\"attention_mask\"]\n",
        "\n",
        "\n",
        "embeddings_list = []\n",
        "for i in tqdm(range(0, len(input_ids), BATCH_SIZE)):\n",
        "    batch_input_ids = input_ids[i:i+BATCH_SIZE]\n",
        "    batch_attention_mask = attention_mask[i:i+BATCH_SIZE]\n",
        "    outputs = distilbert(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "    batch_embeds = tf.reduce_mean(outputs.last_hidden_state, axis=1).numpy()  # mean pooling\n",
        "    embeddings_list.append(batch_embeds)\n",
        "\n",
        "embeddings = np.concatenate(embeddings_list, axis=0)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    embeddings, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "clf = LogisticRegression(max_iter=2000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Accuracy:\", clf.score(X_test, y_test))\n"
      ],
      "metadata": {
        "id": "9vSIUkMx-RBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (distilBERT + logistic regression)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"Logistic Regression Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Frxk_awTAKPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DISTILBERT + XGBOOST**"
      ],
      "metadata": {
        "id": "usGqJYBzIOCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y_raw)\n",
        "\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "distilbert = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\", from_pt=True)\n",
        "distilbert.trainable = False\n",
        "\n",
        "\n",
        "encodings = tokenizer(\n",
        "    X_cleaned,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors=\"tf\"\n",
        ")\n",
        "\n",
        "input_ids = encodings[\"input_ids\"]\n",
        "attention_mask = encodings[\"attention_mask\"]\n",
        "\n",
        "\n",
        "embeddings_list = []\n",
        "for i in tqdm(range(0, len(input_ids), BATCH_SIZE)):\n",
        "    batch_input_ids = input_ids[i:i+BATCH_SIZE]\n",
        "    batch_attention_mask = attention_mask[i:i+BATCH_SIZE]\n",
        "    outputs = distilbert(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "    batch_embeds = tf.reduce_mean(outputs.last_hidden_state, axis=1).numpy()  # mean pooling\n",
        "    embeddings_list.append(batch_embeds)\n",
        "\n",
        "embeddings = np.concatenate(embeddings_list, axis=0)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    embeddings, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "print(\"[INFO] Training XGBoost classifier...\")\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "C4Ud287KISwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (distilbert + xgboost)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\" xgboost Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UlpjTah9KlHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DISTILBERT + RANDOMFOREST**"
      ],
      "metadata": {
        "id": "67_WCECAWnOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y_raw)\n",
        "\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "distilbert = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\", from_pt=True)\n",
        "distilbert.trainable = False\n",
        "\n",
        "\n",
        "encodings = tokenizer(\n",
        "    X_cleaned,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors=\"tf\"\n",
        ")\n",
        "\n",
        "input_ids = encodings[\"input_ids\"]\n",
        "attention_mask = encodings[\"attention_mask\"]\n",
        "\n",
        "\n",
        "embeddings_list = []\n",
        "for i in tqdm(range(0, len(input_ids), BATCH_SIZE)):\n",
        "    batch_input_ids = input_ids[i:i+BATCH_SIZE]\n",
        "    batch_attention_mask = attention_mask[i:i+BATCH_SIZE]\n",
        "    outputs = distilbert(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "    batch_embeds = tf.reduce_mean(outputs.last_hidden_state, axis=1).numpy()  # mean pooling\n",
        "    embeddings_list.append(batch_embeds)\n",
        "\n",
        "embeddings = np.concatenate(embeddings_list, axis=0)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    embeddings, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "print(\"[INFO] Training Random Forest classifier...\")\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=300,       # number of trees\n",
        "    max_depth=20,           # limit depth to avoid overfitting\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "2Pg7c_nuWsWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "y_pred = rf_model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (distilBERT + Randomforest)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"Randdomforest Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "e34e7qzrXbbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DISTILBERT + SVM**"
      ],
      "metadata": {
        "id": "b42zgH_WXa6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y_raw)\n",
        "\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "distilbert = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\", from_pt=True)\n",
        "distilbert.trainable = False\n",
        "\n",
        "\n",
        "encodings = tokenizer(\n",
        "    X_cleaned,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors=\"tf\"\n",
        ")\n",
        "\n",
        "input_ids = encodings[\"input_ids\"]\n",
        "attention_mask = encodings[\"attention_mask\"]\n",
        "\n",
        "\n",
        "embeddings_list = []\n",
        "for i in tqdm(range(0, len(input_ids), BATCH_SIZE)):\n",
        "    batch_input_ids = input_ids[i:i+BATCH_SIZE]\n",
        "    batch_attention_mask = attention_mask[i:i+BATCH_SIZE]\n",
        "    outputs = distilbert(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "    batch_embeds = tf.reduce_mean(outputs.last_hidden_state, axis=1).numpy()  # mean pooling\n",
        "    embeddings_list.append(batch_embeds)\n",
        "\n",
        "embeddings = np.concatenate(embeddings_list, axis=0)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    embeddings, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "print(\"[INFO] Training SVM classifier...\")\n",
        "svm_model = SVC(\n",
        "    kernel='rbf',       # radial basis function kernel\n",
        "    C=10.0,             # regularization parameter\n",
        "    gamma='scale',      # kernel coefficient\n",
        "    probability=True,   # needed if you want predict_proba\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "svm_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "PC6Kmus9qRS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "y_pred = svm_model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (distilBERT + svm)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"svm Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VI4F1ZoCqmMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Roberta + Lstm**"
      ],
      "metadata": {
        "id": "ch0tqY6svB91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer, TFRobertaModel\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, GRU, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 5\n",
        "LR = 1e-4\n",
        "\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_cleaned = label_encoder.fit_transform(y_raw)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y = np.array(y_cleaned)\n",
        "\n",
        "print(\"[INFO] Loading RoBERTa...\")\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "roberta_model = TFRobertaModel.from_pretrained(\"roberta-base\", from_pt=True)\n",
        "\n",
        "\n",
        "roberta_model.trainable = False\n",
        "\n",
        "\n",
        "encodings = tokenizer(\n",
        "    X_cleaned,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors=\"tf\"\n",
        ")\n",
        "\n",
        "input_ids = encodings[\"input_ids\"].numpy()\n",
        "attention_mask = encodings[\"attention_mask\"].numpy()\n",
        "\n",
        "\n",
        "X_train_ids, X_test_ids, X_train_mask, X_test_mask, y_train, y_test = train_test_split(\n",
        "    input_ids, attention_mask, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "class RobertaEmbeddingLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, roberta_model, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.roberta = roberta_model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_ids, attention_mask = inputs\n",
        "        outputs = self.roberta(input_ids, attention_mask=attention_mask)\n",
        "        return outputs.last_hidden_state  # (batch, seq_len, hidden_size)\n",
        "\n",
        "\n",
        "input_ids_layer = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_ids\")\n",
        "attention_mask_layer = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"attention_mask\")\n",
        "\n",
        "roberta_embeddings = RobertaEmbeddingLayer(roberta_model)([input_ids_layer, attention_mask_layer])\n",
        "\n",
        "\n",
        "x = LSTM(128, return_sequences=False, kernel_regularizer=regularizers.l2(1e-4))(roberta_embeddings)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=[input_ids_layer, attention_mask_layer], outputs=outputs)\n",
        "model.compile(optimizer=Adam(learning_rate=LR),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "early_stop = EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train_ids, X_train_mask], y_train,\n",
        "    validation_data=([X_test_ids, X_test_mask], y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate([X_test_ids, X_test_mask], y_test, verbose=0)\n",
        "print(f\"\\n Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eEeC37FyvGV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "y_pred_prob = model.predict([X_test_ids, X_test_mask], batch_size=20)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix ( Roberta + LSTM)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(Roberta + LSTM) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QDG32VLaFIbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Roberta + BILSTM**"
      ],
      "metadata": {
        "id": "-x1gKTheSR_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer, TFRobertaModel\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, GRU, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 5\n",
        "LR = 1e-4\n",
        "\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_cleaned = label_encoder.fit_transform(y_raw)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y = np.array(y_cleaned)\n",
        "\n",
        "print(\"[INFO] Loading RoBERTa...\")\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "roberta_model = TFRobertaModel.from_pretrained(\"roberta-base\", from_pt=True)\n",
        "\n",
        "\n",
        "roberta_model.trainable = False\n",
        "\n",
        "\n",
        "encodings = tokenizer(\n",
        "    X_cleaned,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors=\"tf\"\n",
        ")\n",
        "\n",
        "input_ids = encodings[\"input_ids\"].numpy()\n",
        "attention_mask = encodings[\"attention_mask\"].numpy()\n",
        "\n",
        "\n",
        "X_train_ids, X_test_ids, X_train_mask, X_test_mask, y_train, y_test = train_test_split(\n",
        "    input_ids, attention_mask, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "class RobertaEmbeddingLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, roberta_model, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.roberta = roberta_model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_ids, attention_mask = inputs\n",
        "        outputs = self.roberta(input_ids, attention_mask=attention_mask)\n",
        "        return outputs.last_hidden_state  # (batch, seq_len, hidden_size)\n",
        "\n",
        "\n",
        "input_ids_layer = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_ids\")\n",
        "attention_mask_layer = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"attention_mask\")\n",
        "\n",
        "roberta_embeddings = RobertaEmbeddingLayer(roberta_model)([input_ids_layer, attention_mask_layer])\n",
        "\n",
        "\n",
        "x = Bidirectional(\n",
        "    LSTM(64, return_sequences=False, kernel_regularizer=regularizers.l2(3e-5))\n",
        ")(roberta_embeddings)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=[input_ids_layer, attention_mask_layer], outputs=outputs)\n",
        "model.compile(optimizer=Adam(learning_rate=LR),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "early_stop = EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train_ids, X_train_mask], y_train,\n",
        "    validation_data=([X_test_ids, X_test_mask], y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate([X_test_ids, X_test_mask], y_test, verbose=0)\n",
        "print(f\"\\n Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZLUKxiRNSWLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "y_pred_prob = model.predict([X_test_ids, X_test_mask], batch_size=20)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix ( Roberta + BILSTM)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(Roberta + BILSTM) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CcNdZtHzDoQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, acc, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7Agp5hLBDnjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Roberta + GRU**"
      ],
      "metadata": {
        "id": "UFv4B5_dDyNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer, TFRobertaModel\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, GRU, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 5\n",
        "LR = 1e-4\n",
        "\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_cleaned = label_encoder.fit_transform(y_raw)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y = np.array(y_cleaned)\n",
        "\n",
        "print(\"[INFO] Loading RoBERTa...\")\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "roberta_model = TFRobertaModel.from_pretrained(\"roberta-base\", from_pt=True)\n",
        "\n",
        "\n",
        "roberta_model.trainable = False\n",
        "\n",
        "\n",
        "encodings = tokenizer(\n",
        "    X_cleaned,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors=\"tf\"\n",
        ")\n",
        "\n",
        "input_ids = encodings[\"input_ids\"].numpy()\n",
        "attention_mask = encodings[\"attention_mask\"].numpy()\n",
        "\n",
        "\n",
        "X_train_ids, X_test_ids, X_train_mask, X_test_mask, y_train, y_test = train_test_split(\n",
        "    input_ids, attention_mask, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "class RobertaEmbeddingLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, roberta_model, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.roberta = roberta_model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_ids, attention_mask = inputs\n",
        "        outputs = self.roberta(input_ids, attention_mask=attention_mask)\n",
        "        return outputs.last_hidden_state  # (batch, seq_len, hidden_size)\n",
        "\n",
        "\n",
        "input_ids_layer = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_ids\")\n",
        "attention_mask_layer = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"attention_mask\")\n",
        "\n",
        "roberta_embeddings = RobertaEmbeddingLayer(roberta_model)([input_ids_layer, attention_mask_layer])\n",
        "\n",
        "\n",
        "x = GRU(64, return_sequences=False, kernel_regularizer=regularizers.l2(1e-4))(roberta_embeddings)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=[input_ids_layer, attention_mask_layer], outputs=outputs)\n",
        "model.compile(optimizer=Adam(learning_rate=LR),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "early_stop = EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train_ids, X_train_mask], y_train,\n",
        "    validation_data=([X_test_ids, X_test_mask], y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate([X_test_ids, X_test_mask], y_test, verbose=0)\n",
        "print(f\"\\n Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZLcJJzNgxY0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "y_pred_prob = model.predict([X_test_ids, X_test_mask], batch_size=20)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix ( Roberta + GRU)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(Roberta + GRU ) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2pVrwsFiTpw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, acc, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BOaCRDveWEya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Roberta + BIGRU**"
      ],
      "metadata": {
        "id": "zzloki39vkMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer, TFRobertaModel\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, GRU, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 5\n",
        "LR = 1e-4\n",
        "\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_cleaned = label_encoder.fit_transform(y_raw)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y = np.array(y_cleaned)\n",
        "\n",
        "print(\"[INFO] Loading RoBERTa...\")\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "roberta_model = TFRobertaModel.from_pretrained(\"roberta-base\", from_pt=True)\n",
        "\n",
        "\n",
        "roberta_model.trainable = False\n",
        "\n",
        "\n",
        "encodings = tokenizer(\n",
        "    X_cleaned,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors=\"tf\"\n",
        ")\n",
        "\n",
        "input_ids = encodings[\"input_ids\"].numpy()\n",
        "attention_mask = encodings[\"attention_mask\"].numpy()\n",
        "\n",
        "\n",
        "X_train_ids, X_test_ids, X_train_mask, X_test_mask, y_train, y_test = train_test_split(\n",
        "    input_ids, attention_mask, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "class RobertaEmbeddingLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, roberta_model, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.roberta = roberta_model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_ids, attention_mask = inputs\n",
        "        outputs = self.roberta(input_ids, attention_mask=attention_mask)\n",
        "        return outputs.last_hidden_state  # (batch, seq_len, hidden_size)\n",
        "\n",
        "\n",
        "input_ids_layer = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_ids\")\n",
        "attention_mask_layer = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"attention_mask\")\n",
        "\n",
        "roberta_embeddings = RobertaEmbeddingLayer(roberta_model)([input_ids_layer, attention_mask_layer])\n",
        "\n",
        "\n",
        "x = Bidirectional(GRU(64, return_sequences=False, kernel_regularizer=regularizers.l2(1e-4)))(roberta_embeddings)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=[input_ids_layer, attention_mask_layer], outputs=outputs)\n",
        "model.compile(optimizer=Adam(learning_rate=LR),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "early_stop = EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train_ids, X_train_mask], y_train,\n",
        "    validation_data=([X_test_ids, X_test_mask], y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate([X_test_ids, X_test_mask], y_test, verbose=0)\n",
        "print(f\"\\n Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sq8giJk-vjq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Psj96tYAPC9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "y_pred_prob = model.predict([X_test_ids, X_test_mask], batch_size=20)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix ( Roberta + GRU)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"(Roberta + GRU ) Model Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ftGrMBArvjXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, acc, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uTFgcRNZPEAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Bidirectional(\n",
        "        GRU(64, return_sequences=False, kernel_regularizer=regularizers.l2(1e-4))\n",
        "    )(bert_embeddings)\n",
        "\n",
        "x = Bidirectional(GRU(64, return_sequences=False, kernel_regularizer=regularizers.l2(1e-4)))(roberta_embeddings)\n"
      ],
      "metadata": {
        "id": "7kZ6rtD0C4tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Roberta + Logistc regression**"
      ],
      "metadata": {
        "id": "0-FajL39Vffx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer, TFRobertaModel\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y_raw)\n",
        "\n",
        "\n",
        "print(\"[INFO] Loading RoBERTa...\")\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "roberta_model = TFRobertaModel.from_pretrained(\"roberta-base\", from_pt=True)\n",
        "\n",
        "\n",
        "def get_roberta_embeddings(texts, batch_size=16):\n",
        "    embeddings = []\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Generating embeddings\"):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        encodings = tokenizer(\n",
        "            batch_texts,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=MAX_LEN,\n",
        "            return_tensors=\"tf\"\n",
        "        )\n",
        "        outputs = roberta_model(encodings[\"input_ids\"], attention_mask=encodings[\"attention_mask\"])\n",
        "        cls_embeds = outputs.last_hidden_state[:, 0, :].numpy()\n",
        "        embeddings.append(cls_embeds)\n",
        "    return np.concatenate(embeddings, axis=0)\n",
        "\n",
        "\n",
        "cls_embeddings = get_roberta_embeddings(X_cleaned, batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(cls_embeddings, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "\n",
        "print(\"[INFO] Training Logistic Regression...\")\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = log_reg.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "qmXNV5-sVjUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred = log_reg.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (Roberta + logistic regression)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"Logistic Regression Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lDkUDyO4V82v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Roberta + RandomforestClassifer**"
      ],
      "metadata": {
        "id": "Lf4_lvn1WMQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import RobertaTokenizer, TFRobertaModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y_raw)\n",
        "\n",
        "\n",
        "print(\"[INFO] Loading RoBERTa model...\")\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "roberta_model = TFRobertaModel.from_pretrained(\"roberta-base\", from_pt=True)\n",
        "\n",
        "\n",
        "for layer in roberta_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "print(\"[INFO] Tokenizing texts...\")\n",
        "encodings = tokenizer(\n",
        "    X_cleaned,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors=\"tf\"\n",
        ")\n",
        "\n",
        "input_ids = encodings[\"input_ids\"]\n",
        "attention_mask = encodings[\"attention_mask\"]\n",
        "\n",
        "\n",
        "print(\"[INFO] Generating embeddings in batches...\")\n",
        "embeddings_list = []\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_mask)).batch(BATCH_SIZE)\n",
        "\n",
        "for batch_input_ids, batch_attention_mask in tqdm(dataset, total=len(X_cleaned)//BATCH_SIZE + 1):\n",
        "    outputs = roberta_model(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "    # Mean pooling over token embeddings\n",
        "    batch_embeddings = tf.reduce_mean(outputs.last_hidden_state, axis=1)\n",
        "    embeddings_list.append(batch_embeddings)\n",
        "\n",
        "cls_embeddings = tf.concat(embeddings_list, axis=0).numpy()\n",
        "print(f\"[INFO] Embeddings shape: {cls_embeddings.shape}\")\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    cls_embeddings, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "print(\"[INFO] Training Random Forest classifier...\")\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=20,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = rf_model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\n Test Accuracy: {acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Ui21p9ydWPYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred = rf_model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (Roberta + Randomforest classifeir)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"Randomforestclassifier Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "27YzZ2M-Wi1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Roberta + xgboost**"
      ],
      "metadata": {
        "id": "VejVyudpW5T4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from transformers import RobertaTokenizer, TFRobertaModel\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y_raw)\n",
        "\n",
        "\n",
        "print(\"[INFO] Loading RoBERTa model...\")\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "roberta_model = TFRobertaModel.from_pretrained(\"roberta-base\", from_pt=True)\n",
        "\n",
        "\n",
        "for layer in roberta_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "print(\"[INFO] Tokenizing texts...\")\n",
        "encodings = tokenizer(\n",
        "    X_cleaned,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors=\"tf\"\n",
        ")\n",
        "\n",
        "input_ids = encodings[\"input_ids\"]\n",
        "attention_mask = encodings[\"attention_mask\"]\n",
        "\n",
        "\n",
        "print(\"[INFO] Generating RoBERTa embeddings in batches...\")\n",
        "embeddings_list = []\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_mask)).batch(BATCH_SIZE)\n",
        "\n",
        "for batch_input_ids, batch_attention_mask in tqdm(dataset, total=len(X_cleaned)//BATCH_SIZE + 1):\n",
        "    outputs = roberta_model(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "    # Use mean pooling instead of CLS to reduce noise\n",
        "    batch_embeddings = tf.reduce_mean(outputs.last_hidden_state, axis=1)\n",
        "    embeddings_list.append(batch_embeddings)\n",
        "\n",
        "cls_embeddings = tf.concat(embeddings_list, axis=0).numpy()\n",
        "print(f\"[INFO] Embeddings shape: {cls_embeddings.shape}\")\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    cls_embeddings, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "print(\"[INFO] Training XGBoost classifier...\")\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42,\n",
        "    tree_method='hist',        # memory-efficient\n",
        "    device='cuda' if tf.config.list_physical_devices('GPU') else 'cpu'\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\n Test Accuracy: {acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Daf-W78xXDj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (Roberta + xgboost)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"xgboost Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1K3mJiLkXbc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Roberta + svm**"
      ],
      "metadata": {
        "id": "qiEgvlYvXgmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from transformers import RobertaTokenizer, TFRobertaModel\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "X_cleaned = df['text'].tolist()\n",
        "y_raw = df['Category'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y_raw)\n",
        "\n",
        "\n",
        "print(\"[INFO] Loading RoBERTa model...\")\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "roberta_model = TFRobertaModel.from_pretrained(\"roberta-base\", from_pt=True)\n",
        "\n",
        "# Freeze all layers to save memory\n",
        "for layer in roberta_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "print(\"[INFO] Tokenizing texts...\")\n",
        "encodings = tokenizer(\n",
        "    X_cleaned,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors=\"tf\"\n",
        ")\n",
        "\n",
        "input_ids = encodings[\"input_ids\"]\n",
        "attention_mask = encodings[\"attention_mask\"]\n",
        "\n",
        "\n",
        "print(\"[INFO] Generating RoBERTa embeddings in batches...\")\n",
        "embeddings_list = []\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_mask)).batch(BATCH_SIZE)\n",
        "\n",
        "for batch_input_ids, batch_attention_mask in tqdm(dataset, total=len(X_cleaned)//BATCH_SIZE + 1):\n",
        "    outputs = roberta_model(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "    # Mean pooling over sequence length for stable representation\n",
        "    batch_embeddings = tf.reduce_mean(outputs.last_hidden_state, axis=1)\n",
        "    embeddings_list.append(batch_embeddings)\n",
        "\n",
        "cls_embeddings = tf.concat(embeddings_list, axis=0).numpy()\n",
        "print(f\"[INFO] Embeddings shape: {cls_embeddings.shape}\")  # (samples, 768)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    cls_embeddings, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(\"[INFO] Training SVM classifier...\")\n",
        "svm_model = SVC(\n",
        "    kernel='rbf',\n",
        "    C=10.0,\n",
        "    gamma='scale',\n",
        "    probability=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = svm_model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\n Test Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "snNHU5ZZXjhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred = svm_model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix (Roberta + xgboost)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "scores = [acc, prec, rec, f1]\n",
        "labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bars = plt.bar(labels, scores, color=['skyblue','lightgreen','salmon','orange'])\n",
        "for bar, score in zip(bars, scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f\"{score:.2f}\", ha='center', va='bottom', fontsize=12, fontweight=\"bold\")\n",
        "plt.ylim(0,1.1)\n",
        "plt.title(\"xgboost Performance Metrics\", fontsize=14, fontweight=\"bold\")\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BKKTZ8QLX3n8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}